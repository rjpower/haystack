{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/power/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "EMBED_MODEL = 'mixedbread-ai/mxbai-embed-large-v1'\n",
    "\n",
    "import datasets\n",
    "ds = datasets.load_dataset('mikex86/stackoverflow-posts', split='train', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 An explicit cast to `double` like this isn't necessary:\n",
      "\n",
      "```\n",
      "double trans = (double) trackBar1.Value / 5000.0;\n",
      "```\n",
      "\n",
      "\n",
      "Identifying the constant as `5000.0` (or as `5000d`) is sufficient:\n",
      "\n",
      "```\n",
      "double trans = trackBar1.Value / 5000.0;\n",
      "double trans = trackBar1.Value / 5000d;\n",
      "```\n",
      "\n",
      "\n",
      "1 Given a `DateTime` representing a person's birthday, how do I calculate their age in years?\n",
      "\n",
      "2 Given a specific `DateTime` value, how do I display relative time, like:\n",
      "- `2 hours ago`- `3 days ago`- `a month ago`\n",
      "\n",
      "3 What is the difference between [Math.Floor()](http://msdn.microsoft.com/en-us/library/9a6a2sxy.aspx) and [Math.Truncate()](http://msdn.microsoft.com/en-us/library/system.math.truncate.aspx) in .NET?\n",
      "\n",
      "4 I have an absolutely positioned `div` containing several children, one of which is a relatively positioned `div`. When I use a `percentage-based width` on the child `div`, it collapses to `0 width` on IE7, but not on Firefox or Safari.\n",
      "If I use `pixel width`, it works. If the parent is relatively positioned, the percentage width on the child works.\n",
      "\n",
      "1. Is there something I'm missing here?\n",
      "2. Is there an easy fix for this besides the pixel-based width on the child?\n",
      "3. Is there an area of the CSS specification that covers this?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(iter(ds)):\n",
    "  print(i, sample[\"Body\"])\n",
    "  if i > 3:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[  101,  2019, 13216,  3459,  2000,  1036,  3313,  1036,  2066,\n",
      "         2023,  3475,  1005,  1056,  4072,  1024,  1036,  1036,  1036,\n",
      "         3313,  9099,  1027,  1006,  3313,  1007,  2650,  8237,  2487,\n",
      "         1012,  3643,  1013, 13509,  1012,  1014,  1025,  1036,  1036,\n",
      "         1036, 12151,  1996,  5377,  2004,  1036, 13509,  1012,  1014,\n",
      "         1036,  1006,  2030,  2004,  1036, 13509,  2094,  1036,  1007,\n",
      "         2003,  7182,  1024,  1036,  1036,  1036,  3313,  9099,  1027,\n",
      "         2650,  8237,  2487,  1012,  3643,  1013, 13509,  1012,  1014,\n",
      "         1025,  3313,  9099,  1027,  2650,  8237,  2487,  1012,  3643,\n",
      "         1013, 13509,  2094,  1025,  1036,  1036,  1036,   102]]), 'token_type_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1]])}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(EMBED_MODEL)\n",
    "\n",
    "body = next(iter(ds))['Body']\n",
    "input_ids = tokenizer(body, return_tensors=\"np\")\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModel.from_pretrained(EMBED_MODEL).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_input_ids torch.Size([160, 16]) torch.int64 cpu\n",
      "key_token_type_ids torch.Size([160, 16]) torch.int64 cpu\n",
      "key_attention_mask torch.Size([160, 16]) torch.int64 cpu\n",
      "value_input_ids torch.Size([160, 32]) torch.int64 cpu\n",
      "value_token_type_ids torch.Size([160, 32]) torch.int64 cpu\n",
      "value_attention_mask torch.Size([160, 32]) torch.int64 cpu\n",
      "0 (1024,)\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "3 (1024,)\n",
      "4 (1024,)\n",
      "5 (1024,)\n",
      "6 (1024,)\n",
      "7 (1024,)\n",
      "8 (1024,)\n",
      "9 (1024,)\n",
      "10 (1024,)\n",
      "11 (1024,)\n",
      "12 (1024,)\n",
      "13 (1024,)\n",
      "14 (1024,)\n",
      "15 (1024,)\n",
      "16 (1024,)\n",
      "17 (1024,)\n",
      "18 (1024,)\n",
      "19 (1024,)\n",
      "20 (1024,)\n",
      "21 (1024,)\n",
      "22 (1024,)\n",
      "23 (1024,)\n",
      "24 (1024,)\n",
      "25 (1024,)\n",
      "26 (1024,)\n",
      "27 (1024,)\n",
      "28 (1024,)\n",
      "29 (1024,)\n",
      "30 (1024,)\n",
      "31 (1024,)\n",
      "32 (1024,)\n",
      "33 (1024,)\n",
      "34 (1024,)\n",
      "35 (1024,)\n",
      "36 (1024,)\n",
      "37 (1024,)\n",
      "38 (1024,)\n",
      "39 (1024,)\n",
      "40 (1024,)\n",
      "41 (1024,)\n",
      "42 (1024,)\n",
      "43 (1024,)\n",
      "44 (1024,)\n",
      "45 (1024,)\n",
      "46 (1024,)\n",
      "47 (1024,)\n",
      "48 (1024,)\n",
      "49 (1024,)\n",
      "50 (1024,)\n",
      "51 (1024,)\n",
      "52 (1024,)\n",
      "53 (1024,)\n",
      "54 (1024,)\n",
      "55 (1024,)\n",
      "56 (1024,)\n",
      "57 (1024,)\n",
      "58 (1024,)\n",
      "59 (1024,)\n",
      "60 (1024,)\n",
      "61 (1024,)\n",
      "62 (1024,)\n",
      "63 (1024,)\n",
      "64 (1024,)\n",
      "65 (1024,)\n",
      "66 (1024,)\n",
      "67 (1024,)\n",
      "68 (1024,)\n",
      "69 (1024,)\n",
      "70 (1024,)\n",
      "71 (1024,)\n",
      "72 (1024,)\n",
      "73 (1024,)\n",
      "74 (1024,)\n",
      "75 (1024,)\n",
      "76 (1024,)\n",
      "77 (1024,)\n",
      "78 (1024,)\n",
      "79 (1024,)\n",
      "80 (1024,)\n",
      "81 (1024,)\n",
      "82 (1024,)\n",
      "83 (1024,)\n",
      "84 (1024,)\n",
      "85 (1024,)\n",
      "86 (1024,)\n",
      "87 (1024,)\n",
      "88 (1024,)\n",
      "89 (1024,)\n",
      "90 (1024,)\n",
      "91 (1024,)\n",
      "92 (1024,)\n",
      "93 (1024,)\n",
      "94 (1024,)\n",
      "95 (1024,)\n",
      "96 (1024,)\n",
      "97 (1024,)\n",
      "98 (1024,)\n",
      "99 (1024,)\n",
      "100 (1024,)\n",
      "101 (1024,)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dataset until we have processed 10M tokens.\n",
    "# For each set of KEY_WINDOW tokens, compute the embeddings and store them in a list.\n",
    "\n",
    "KEY_WINDOW = 16\n",
    "VALUE_WINDOW = 32\n",
    "MAX_DOCS = 1000\n",
    "\n",
    "docs = []\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "DS_KEYS = list(next(iter(ds)).keys())\n",
    "\n",
    "\n",
    "def split(record):\n",
    "    result = {\n",
    "        \"key_input_ids\": [],\n",
    "        \"key_token_type_ids\": [],\n",
    "        \"key_attention_mask\": [],\n",
    "        \"value_input_ids\": [],\n",
    "        \"value_token_type_ids\": [],\n",
    "        \"value_attention_mask\": [],\n",
    "    }\n",
    "\n",
    "    num_docs = record['input_ids'].shape[0]\n",
    "    for i in range(num_docs):\n",
    "        for j in range(0, record['input_ids'][i].shape[0], KEY_WINDOW):\n",
    "            result[\"key_input_ids\"].append(record[\"input_ids\"][i][j : j + KEY_WINDOW])\n",
    "            result[\"key_token_type_ids\"].append(record[\"token_type_ids\"][i][j : j + KEY_WINDOW])\n",
    "            result[\"key_attention_mask\"].append(record[\"attention_mask\"][i][j : j + KEY_WINDOW])\n",
    "            result[\"value_input_ids\"].append(record[\"input_ids\"][i][j : j + VALUE_WINDOW])\n",
    "            result[\"value_token_type_ids\"].append(record[\"token_type_ids\"][i][j: j + VALUE_WINDOW])\n",
    "            result[\"value_attention_mask\"].append(record[\"attention_mask\"][i][j: j + VALUE_WINDOW])\n",
    "\n",
    "    # Convert to torch tensors, padding to the maximum length\n",
    "    for k, v in result.items():\n",
    "        result[k] = torch.tensor(\n",
    "            np.array(list(itertools.zip_longest(*v, fillvalue=0))).T\n",
    "        )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def encode(record):\n",
    "    tokens = tokenizer(record[\"Body\"], padding=True, return_tensors=\"np\")\n",
    "    splits = split(tokens)\n",
    "    for k, v in splits.items():\n",
    "        splits[k] = v.cuda()\n",
    "        print(k, v.shape, v.dtype, v.device)\n",
    "\n",
    "    key_embedding = model(\n",
    "        input_ids=splits[\"key_input_ids\"],\n",
    "        token_type_ids=splits[\"key_token_type_ids\"],\n",
    "        attention_mask=splits[\"key_attention_mask\"],\n",
    "    ).last_hidden_state\n",
    "\n",
    "    value_embedding = model(\n",
    "        input_ids=splits[\"value_input_ids\"],\n",
    "        token_type_ids=splits[\"value_token_type_ids\"],\n",
    "        attention_mask=splits[\"value_attention_mask\"],\n",
    "    ).last_hidden_state\n",
    "\n",
    "    return {\n",
    "        \"key_embedding\": key_embedding[:, 0].detach().cpu().numpy(),\n",
    "        \"value_embedding\": value_embedding[:, 0].detach().cpu().numpy(),\n",
    "    }\n",
    "\n",
    "\n",
    "encode_ds = ds.map(\n",
    "    encode,\n",
    "    batch_size=8,\n",
    "    batched=True,\n",
    "    remove_columns=DS_KEYS,\n",
    ")\n",
    "\n",
    "for i, sample in enumerate(iter(encode_ds)):\n",
    "    print(i, sample['key_embedding'].shape)\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
