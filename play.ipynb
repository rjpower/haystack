{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/power/code/haystack/.conda/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AnglE:Prompt is set, the prompt will be automatically applied during the encoding phase. To disable prompt setting, please configure set_prompt(prompt=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import haystack\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "haystack = importlib.reload(haystack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ad24aa206e4c2b9b7df47d7609acc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HaystackForCausalLM were not initialized from the model checkpoint at google/gemma-2b and are newly initialized: ['model.db.db.weight', 'model.db.embedding_to_hidden.bias', 'model.db.embedding_to_hidden.weight', 'model.db.hidden_to_key.bias', 'model.db.hidden_to_key.weight', 'model.db.keys.bias', 'model.db.keys.weight', 'model.layers.0.db_layer.db.weight', 'model.layers.0.db_layer.embedding_to_hidden.bias', 'model.layers.0.db_layer.embedding_to_hidden.weight', 'model.layers.0.db_layer.hidden_to_key.bias', 'model.layers.0.db_layer.hidden_to_key.weight', 'model.layers.0.db_layer.keys.bias', 'model.layers.0.db_layer.keys.weight', 'model.layers.1.db_layer.db.weight', 'model.layers.1.db_layer.embedding_to_hidden.bias', 'model.layers.1.db_layer.embedding_to_hidden.weight', 'model.layers.1.db_layer.hidden_to_key.bias', 'model.layers.1.db_layer.hidden_to_key.weight', 'model.layers.1.db_layer.keys.bias', 'model.layers.1.db_layer.keys.weight', 'model.layers.10.db_layer.db.weight', 'model.layers.10.db_layer.embedding_to_hidden.bias', 'model.layers.10.db_layer.embedding_to_hidden.weight', 'model.layers.10.db_layer.hidden_to_key.bias', 'model.layers.10.db_layer.hidden_to_key.weight', 'model.layers.10.db_layer.keys.bias', 'model.layers.10.db_layer.keys.weight', 'model.layers.11.db_layer.db.weight', 'model.layers.11.db_layer.embedding_to_hidden.bias', 'model.layers.11.db_layer.embedding_to_hidden.weight', 'model.layers.11.db_layer.hidden_to_key.bias', 'model.layers.11.db_layer.hidden_to_key.weight', 'model.layers.11.db_layer.keys.bias', 'model.layers.11.db_layer.keys.weight', 'model.layers.12.db_layer.db.weight', 'model.layers.12.db_layer.embedding_to_hidden.bias', 'model.layers.12.db_layer.embedding_to_hidden.weight', 'model.layers.12.db_layer.hidden_to_key.bias', 'model.layers.12.db_layer.hidden_to_key.weight', 'model.layers.12.db_layer.keys.bias', 'model.layers.12.db_layer.keys.weight', 'model.layers.13.db_layer.db.weight', 'model.layers.13.db_layer.embedding_to_hidden.bias', 'model.layers.13.db_layer.embedding_to_hidden.weight', 'model.layers.13.db_layer.hidden_to_key.bias', 'model.layers.13.db_layer.hidden_to_key.weight', 'model.layers.13.db_layer.keys.bias', 'model.layers.13.db_layer.keys.weight', 'model.layers.14.db_layer.db.weight', 'model.layers.14.db_layer.embedding_to_hidden.bias', 'model.layers.14.db_layer.embedding_to_hidden.weight', 'model.layers.14.db_layer.hidden_to_key.bias', 'model.layers.14.db_layer.hidden_to_key.weight', 'model.layers.14.db_layer.keys.bias', 'model.layers.14.db_layer.keys.weight', 'model.layers.15.db_layer.db.weight', 'model.layers.15.db_layer.embedding_to_hidden.bias', 'model.layers.15.db_layer.embedding_to_hidden.weight', 'model.layers.15.db_layer.hidden_to_key.bias', 'model.layers.15.db_layer.hidden_to_key.weight', 'model.layers.15.db_layer.keys.bias', 'model.layers.15.db_layer.keys.weight', 'model.layers.16.db_layer.db.weight', 'model.layers.16.db_layer.embedding_to_hidden.bias', 'model.layers.16.db_layer.embedding_to_hidden.weight', 'model.layers.16.db_layer.hidden_to_key.bias', 'model.layers.16.db_layer.hidden_to_key.weight', 'model.layers.16.db_layer.keys.bias', 'model.layers.16.db_layer.keys.weight', 'model.layers.17.db_layer.db.weight', 'model.layers.17.db_layer.embedding_to_hidden.bias', 'model.layers.17.db_layer.embedding_to_hidden.weight', 'model.layers.17.db_layer.hidden_to_key.bias', 'model.layers.17.db_layer.hidden_to_key.weight', 'model.layers.17.db_layer.keys.bias', 'model.layers.17.db_layer.keys.weight', 'model.layers.2.db_layer.db.weight', 'model.layers.2.db_layer.embedding_to_hidden.bias', 'model.layers.2.db_layer.embedding_to_hidden.weight', 'model.layers.2.db_layer.hidden_to_key.bias', 'model.layers.2.db_layer.hidden_to_key.weight', 'model.layers.2.db_layer.keys.bias', 'model.layers.2.db_layer.keys.weight', 'model.layers.3.db_layer.db.weight', 'model.layers.3.db_layer.embedding_to_hidden.bias', 'model.layers.3.db_layer.embedding_to_hidden.weight', 'model.layers.3.db_layer.hidden_to_key.bias', 'model.layers.3.db_layer.hidden_to_key.weight', 'model.layers.3.db_layer.keys.bias', 'model.layers.3.db_layer.keys.weight', 'model.layers.4.db_layer.db.weight', 'model.layers.4.db_layer.embedding_to_hidden.bias', 'model.layers.4.db_layer.embedding_to_hidden.weight', 'model.layers.4.db_layer.hidden_to_key.bias', 'model.layers.4.db_layer.hidden_to_key.weight', 'model.layers.4.db_layer.keys.bias', 'model.layers.4.db_layer.keys.weight', 'model.layers.5.db_layer.db.weight', 'model.layers.5.db_layer.embedding_to_hidden.bias', 'model.layers.5.db_layer.embedding_to_hidden.weight', 'model.layers.5.db_layer.hidden_to_key.bias', 'model.layers.5.db_layer.hidden_to_key.weight', 'model.layers.5.db_layer.keys.bias', 'model.layers.5.db_layer.keys.weight', 'model.layers.6.db_layer.db.weight', 'model.layers.6.db_layer.embedding_to_hidden.bias', 'model.layers.6.db_layer.embedding_to_hidden.weight', 'model.layers.6.db_layer.hidden_to_key.bias', 'model.layers.6.db_layer.hidden_to_key.weight', 'model.layers.6.db_layer.keys.bias', 'model.layers.6.db_layer.keys.weight', 'model.layers.7.db_layer.db.weight', 'model.layers.7.db_layer.embedding_to_hidden.bias', 'model.layers.7.db_layer.embedding_to_hidden.weight', 'model.layers.7.db_layer.hidden_to_key.bias', 'model.layers.7.db_layer.hidden_to_key.weight', 'model.layers.7.db_layer.keys.bias', 'model.layers.7.db_layer.keys.weight', 'model.layers.8.db_layer.db.weight', 'model.layers.8.db_layer.embedding_to_hidden.bias', 'model.layers.8.db_layer.embedding_to_hidden.weight', 'model.layers.8.db_layer.hidden_to_key.bias', 'model.layers.8.db_layer.hidden_to_key.weight', 'model.layers.8.db_layer.keys.bias', 'model.layers.8.db_layer.keys.weight', 'model.layers.9.db_layer.db.weight', 'model.layers.9.db_layer.embedding_to_hidden.bias', 'model.layers.9.db_layer.embedding_to_hidden.weight', 'model.layers.9.db_layer.hidden_to_key.bias', 'model.layers.9.db_layer.hidden_to_key.weight', 'model.layers.9.db_layer.keys.bias', 'model.layers.9.db_layer.keys.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "\n",
    "model = haystack.HaystackForCausalLM.from_pretrained(\"google/gemma-2b\")\n",
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/power/code/haystack/.conda/lib/python3.11/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 9]) torch.Size([1, 10]) tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "Layer:  0 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  1 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  2 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  3 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  4 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  5 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  6 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  7 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  8 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  9 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  10 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  11 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  12 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  13 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  14 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  15 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  16 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Layer:  17 torch.Size([1, 9, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 10]) DynamicCache() False True tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Before Rotary:  torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10, 256]) torch.Size([1, 10])\n",
      "Rotary Pos Embed torch.Size([1, 8, 10, 256]) torch.Size([1, 1, 10, 256]) torch.Size([1, 1, 10, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 10]) torch.Size([1, 11]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "Layer:  0 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  1 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  2 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  3 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  4 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  5 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  6 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  7 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  8 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  9 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  10 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  11 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  12 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  13 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  14 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  15 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  16 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Layer:  17 torch.Size([1, 10, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 11]) DynamicCache() False True tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "Before Rotary:  torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11, 256]) torch.Size([1, 11])\n",
      "Rotary Pos Embed torch.Size([1, 8, 11, 256]) torch.Size([1, 1, 11, 256]) torch.Size([1, 1, 11, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 11]) torch.Size([1, 12]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])\n",
      "Layer:  0 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  1 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  2 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  3 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  4 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  5 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  6 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  7 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  8 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  9 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  10 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  11 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  12 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  13 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  14 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  15 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  16 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Layer:  17 torch.Size([1, 11, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 12]) DynamicCache() False True tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "Before Rotary:  torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12, 256]) torch.Size([1, 12])\n",
      "Rotary Pos Embed torch.Size([1, 8, 12, 256]) torch.Size([1, 1, 12, 256]) torch.Size([1, 1, 12, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 12]) torch.Size([1, 13]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])\n",
      "Layer:  0 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  1 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  2 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  3 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  4 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  5 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  6 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  7 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  8 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  9 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  10 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  11 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  12 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  13 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  14 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  15 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  16 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Layer:  17 torch.Size([1, 12, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 13]) DynamicCache() False True tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])\n",
      "Before Rotary:  torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13, 256]) torch.Size([1, 13])\n",
      "Rotary Pos Embed torch.Size([1, 8, 13, 256]) torch.Size([1, 1, 13, 256]) torch.Size([1, 1, 13, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 13]) torch.Size([1, 14]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13]])\n",
      "Layer:  0 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  1 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  2 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  3 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  4 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  5 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  6 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  7 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  8 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  9 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  10 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  11 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  12 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  13 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  14 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  15 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  16 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Layer:  17 torch.Size([1, 13, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 14]) DynamicCache() False True tensor([46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "Before Rotary:  torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14, 256]) torch.Size([1, 14])\n",
      "Rotary Pos Embed torch.Size([1, 8, 14, 256]) torch.Size([1, 1, 14, 256]) torch.Size([1, 1, 14, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 14]) torch.Size([1, 15]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]])\n",
      "Layer:  0 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  1 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  2 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  3 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  4 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  5 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  6 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  7 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  8 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  9 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  10 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  11 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  12 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  13 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  14 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  15 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  16 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Layer:  17 torch.Size([1, 14, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 15]) DynamicCache() False True tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
      "Before Rotary:  torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15, 256]) torch.Size([1, 15])\n",
      "Rotary Pos Embed torch.Size([1, 8, 15, 256]) torch.Size([1, 1, 15, 256]) torch.Size([1, 1, 15, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 15]) torch.Size([1, 16]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "Layer:  0 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  1 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  2 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  3 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  4 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  5 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  6 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  7 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  8 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  9 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  10 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  11 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  12 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  13 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  14 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  15 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  16 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Layer:  17 torch.Size([1, 15, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 16]) DynamicCache() False True tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n",
      "Before Rotary:  torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16, 256]) torch.Size([1, 16])\n",
      "Rotary Pos Embed torch.Size([1, 8, 16, 256]) torch.Size([1, 1, 16, 256]) torch.Size([1, 1, 16, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 16]) torch.Size([1, 17]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]])\n",
      "Layer:  0 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  1 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  2 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  3 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  4 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  5 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  6 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  7 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  8 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  9 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  10 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  11 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  12 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  13 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  14 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  15 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  16 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Layer:  17 torch.Size([1, 16, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 17]) DynamicCache() False True tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107])\n",
      "Before Rotary:  torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17, 256]) torch.Size([1, 17])\n",
      "Rotary Pos Embed torch.Size([1, 8, 17, 256]) torch.Size([1, 1, 17, 256]) torch.Size([1, 1, 17, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 17]) torch.Size([1, 18]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]])\n",
      "Layer:  0 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  1 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  2 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  3 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  4 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  5 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  6 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  7 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  8 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  9 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  10 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  11 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  12 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  13 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  14 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  15 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  16 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Layer:  17 torch.Size([1, 17, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 18]) DynamicCache() False True tensor([108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125])\n",
      "Before Rotary:  torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18, 256]) torch.Size([1, 18])\n",
      "Rotary Pos Embed torch.Size([1, 8, 18, 256]) torch.Size([1, 1, 18, 256]) torch.Size([1, 1, 18, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 18]) torch.Size([1, 19]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18]])\n",
      "Layer:  0 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  1 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  2 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  3 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  4 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  5 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  6 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  7 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  8 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  9 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  10 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  11 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  12 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  13 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  14 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  15 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  16 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Layer:  17 torch.Size([1, 18, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 19]) DynamicCache() False True tensor([126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144])\n",
      "Before Rotary:  torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19, 256]) torch.Size([1, 19])\n",
      "Rotary Pos Embed torch.Size([1, 8, 19, 256]) torch.Size([1, 1, 19, 256]) torch.Size([1, 1, 19, 256])\n",
      "Position ids? None\n",
      "Prepare:  torch.Size([1, 19]) torch.Size([1, 20]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19]])\n",
      "Layer:  0 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  1 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  2 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  3 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  4 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  5 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  6 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  7 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  8 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  9 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  10 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  11 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  12 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  13 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  14 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  15 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  16 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "Layer:  17 torch.Size([1, 19, 2048]) torch.Size([1, 1, 8192, 8192]) torch.Size([1, 20]) DynamicCache() False True tensor([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164])\n",
      "Before Rotary:  torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20, 256]) torch.Size([1, 20])\n",
      "Rotary Pos Embed torch.Size([1, 8, 20, 256]) torch.Size([1, 1, 20, 256]) torch.Size([1, 1, 20, 256])\n",
      "<bos>Write me a poem about Machine Learning. burberry tremb reluct reluct reluct reluct reluct reluct reluct reluct reluct\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7b31de84a4439f8542f3ad46899059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: aca28e26-5880-462f-9ee0-391219ddd2d8)')' thrown while requesting GET https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-2-raw-v1/test-00000-of-00001.parquet\n",
      "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: aca28e26-5880-462f-9ee0-391219ddd2d8)')' thrown while requesting GET https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-2-raw-v1/test-00000-of-00001.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
      "Downloading data: 100%|██████████| 733k/733k [00:01<00:00, 544kB/s]\n",
      "Downloading data: 100%|██████████| 6.36M/6.36M [00:00<00:00, 24.8MB/s]\n",
      "Downloading data: 100%|██████████| 657k/657k [00:00<00:00, 4.91MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16558100aa24be483434ea2a839a4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfa7b92ac9740dfb2714a248243aaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790a29519587452baefe2fd93670fc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1e6771606a493880959da1a5743722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea5461af0a746348157a0af6f6a4ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4827d847e2324f3e96104c22b3214dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 589, 164672, 4016, 81321, 5638, 589, 235248, 108],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693c1b4fd12b4b4585e1c061598b70a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c51b77b30c45708dbbcfac03b0ace4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b839d0277a074a09accf07937942c2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose face in the war . While at times this works to their advantage , such as a successful incursion into Imperial territory , other orders cause certain members of the 422nd great distress . One such member , Gusurg , becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven , attached to the ideal of Darcsen independence proposed by their leader , Dahau . At the same time , elements within Gallian Army Command move to erase the Nameless in order to protect their own'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][10][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "model_name = 'haystack-v0'\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
